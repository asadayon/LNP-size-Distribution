# -*- coding: utf-8 -*-
"""LNPs_size_distribution_homogeneity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qQv71czaE7o-RqnhWkytLQGxp3iLIKIE
"""

from google.colab import drive
drive.mount('/content/drive')

#!/usr/bin/env python
# coding: utf-8

# In[90]:


import numpy as np
import cv2
import csv
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
from matplotlib import pylab

import matplotlib as mpl


def get_tem_scale(img_path,y1=None,y2=None,x1=None,x2=None, threshold_type = cv2.THRESH_BINARY,lower_thresh = 220):

    '''
    This function takes in an image and tries to find the scale by measuring the line segment usually given at the bottom left
    if the TEM micrograph. It approximates a rectangle for this and reports the width of rectangle as the scale.

    Adjust the crop paramters x1,x2,y1 and y2 to fit the scale within the cropped area.

    Parameters:
    img_path :  Path of the TEM image.
    y1 = start index for cropping along vertical axis, must be an integer.
    y2 = end index for cropping along vertical axis, must be an integer.
    x1 = start index for cropping along horizontal axis, must be an integer.
    x2 = end index for cropping along horizontal axis, must be an integer.

    Prints width of the approximating rectangle.

    '''

    img = cv2.imread(img_path)
    print(img.shape)
    '''
    if np.any(img):
        pass
    else:
        print('Image could not be read, check path or check if image is corrupt.')
        return None
    '''
    if y1 == None:
        y1 = int(0.85*img.shape[0])
    if y2 == None:
        y2 = int(0.99*img.shape[0])
    if x1 == None:
        x1 = 0
    if x2 == None:
        x2 = int(0.5*img.shape[1])

    crop_img = img[y1:y2,0:x2]

    if np.any(crop_img):
        pass
    else:
        print('Cropped Image is empty, check crop dimensions.')

    imshow(crop_img)
    scale_gray = cv2.cvtColor(crop_img,cv2.COLOR_BGR2GRAY)

    # choose threshold type  as cv2.THRESH_BINARY_INV if scale region is black.
    if threshold_type == cv2.THRESH_BINARY_INV:
        lower_thresh = 0
    ret, thresh = cv2.threshold(scale_gray, lower_thresh, 255, threshold_type)
    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # filter noisy detection
    contours = [c for c in contours if cv2.contourArea(c) > 200]
    contours.sort(key=lambda c: (cv2.boundingRect(c)[1], cv2.boundingRect(c)[0]))

    x,y,w,h = cv2.boundingRect(contours[-1])
    thresh=cv2.rectangle(thresh, (x,y),(x+w,y+h+30), (0,0,255), 20)
    print('x : %f , y = %f , w = %f , h = %f '%(x,y,w,h))
    print('The length of the pixel in pixels is : ',w)
    #cv2.imshow('scale_marked',crop_img)
    imshow(thresh)
    cv2.imwrite('/content/scale.jpg',thresh)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    return y



def find_particles(img_path,scale=None,thresh = 80,save_images = True):

    '''
    This function finds particles by contouring, Image which is loade converted to grayscale.
    A gaussian Blur is then used to remove a bit of noise in the images, which helps with over-detection.
    Threshold style by default is cv2.THRESH_BINARY.

    Threshold by default is 45. Change this according to your data.

    Parameters:
    img_path :  Path of the TEM image.
    scale : Either already known or found from get_tem_scale()
    thresh :  lower limit of threshold.
    save_images : If true, the images are saved to same directory as the original images, False by default.

    '''
    # Read the image
    img = cv2.imread(img_path)
    '''
    if np.any(img):
        pass
    else:
        print('Image could not be read, check path or check if image is corrupt.')
        return None
    '''
    #img = cv2.resize(img,(0,0),fx=0.25,fy=0.25)
    print(img.shape)
    # Gaussian Blur ot reduce noise
    #img = cv2.GaussianBlur(img,(5,5),0)
    img =   cv2.medianBlur(img, 5)
    # convert to grascale
    gray= cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)

    # thresholding, making a binary image.
    ret,thresh = cv2.threshold(gray,thresh,255,cv2.THRESH_BINARY)
    thresh = cv2.Canny(thresh, 30, 150)
    #ret3,thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
    #img_thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,1151,1)
    #cv2.namedWindow("Threshold image", cv2.WINDOW_NORMAL)
    #cv2.imshow('Threshold image',thresh)
    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
    img2 = img.copy()

    index = -1
    thickness = 1
    color = (255,0,0)
    '''
    # drawing contours.
    cv2.drawContours(img2,contours,index,color,thickness)
    cv2.namedWindow("contours", cv2.WINDOW_NORMAL)

    #cv2.imshow('contours',img2)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    '''
    cv2.drawContours(img2,contours,index,color,thickness)
    # saving images
    if save_images==True:
        cv2.imwrite(img_path+'_thresh.tif',thresh)
        cv2.imwrite(img_path+'_contours.tif',img2)
    return contours


# #### Step 3: Plot the size distribution.

# In[93]:


def size_distribution_plot(img_path,contours=None,scale=None,main_scale=None,r_min=.16,r_max=2, bins=None, save_fig = True):

    '''
    This generates a size ditribtution plot, the sizes can be managed by r_min and r_max.

    Parameters :
    img_path :  Path of the TEM image.
    contours: Obatained from find_particles()
    scale : Already known or found from get_tem_scale()
    r_min :  Minimum radius of particles to be marked. By default, it is equal to scale.
    r_max = Maximum radius of particles to be marked. By default, it is 100 times the scale.
    bins :  bins in the histogram which is plotted.

    Prints the mean particles size. (Note that the diameters are returned.)
    If you want to exclude all particles under 10 nm, give r_max as 5.
    Returns an array of particle sizes.

    '''

    # Change this according to your data.
    if r_min == None:
        r_min = 0.5*scale
    if r_max == None:
        r_max = 50*scale
    #######

    img = cv2.imread(img_path)
    '''
    if np.any(img):
        pass
    else:
        print('Image could not be read, check path or check if image is corrupt.')
        return None
    '''
    fig,ax = plt.subplots(1,2,figsize=(30,80))
    ax[0].imshow(img)
    ax[1].imshow(img)
    sizes = []
    size_2=[]
    mn=100
    mx=0
    center_cal=[]
    for i in range(len(contours)):
        cnt = contours[i]
        (x,y),radius = cv2.minEnclosingCircle(cnt)
        center = (int(x),int(y))
        radius=int(radius)
        if radius > r_min*scale and radius < r_max*scale:
            sizes.append(radius)
            center_cal.append(center)
            size_2.append(int(((radius*main_scale)/scale)))
            c=plt.Circle((x,y),radius,color='r' ,linewidth=2, fill=False)
            # commented out in case of a lot of particles, it is a very messy plot.
            #ax[1].annotate(str(i),(x,y))

            ax[1].add_patch(c)
    plt.savefig(img_path+'_particle.jpg')
    sizes = (np.array(sizes)*2) # Note that these are diameters
    #print(sizes)
    print(size_2)
    fig1,ax1 = plt.subplots()
    if bins == None:
        bins = len(set(sizes))
    #print(bins)
    ax1.hist(sizes,color='#98ff98', histtype='bar', ec='black', bins=bins)

    plt.xlabel('Diameter (nm)')
    plt.ylabel('Number of particles')
    print('Mean diameter : %0.2f'%(np.mean(size_2)))
    print('Total Particles : %g'%(len(size_2)))

    if save_fig == True:
        plt.savefig(img_path+'_analysis.png')
    particle={}
    for i in size_2:
        particle[i]=0
    for i in size_2:
        particle[i]+=1
    with open('Diameter_distribution.csv', 'w') as file:
      states_writer = csv.writer(file)
      for i in particle:
          states_writer.writerow([i, particle[i]])
    plt.tight_layout()
    plt.show()
    return np.sort(sizes), center_cal


path='/content/drive/MyDrive/Research/Farhana project/LNPs Cryo_TEM Dataset/main/26.jpg'
print(path)
image = cv2.imread(path)
cv2.imwrite('tem.jpg', image)

scal=get_tem_scale(path)


path='/content/Detected_particle[1].jpg'

contour=find_particles(path, scale=scal)

a,center_cal=size_distribution_plot(path,contours=contour,scale=scal,main_scale=200)
